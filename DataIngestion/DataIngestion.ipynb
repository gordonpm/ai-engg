{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a text file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "textLoader = TextLoader('speech.txt')\n",
    "textLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf40d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_document = textLoader.load()\n",
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a PDF file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdfLoader = PyPDFLoader('attention.pdf')\n",
    "pdf_document = pdfLoader.load()\n",
    "pdf_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d011cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pdf_document[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b72e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a web page\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "webLoader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "                     ))\n",
    "                     )\n",
    "web_document = webLoader.load()\n",
    "web_document[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "arxivdoc = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4fa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxivdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42788124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu and Yandex.\\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu and Yandex.\\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.\\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural networks (2014â€“2019) ===\\n\\nMachine learning uses both discriminative models and generative models to predict data. Beginning in the late 2000s, the introduction of deep learning technology led to improvements in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images, ')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Wikipedia\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "wikidoc = WikipediaLoader(query=\"Generative AI\", load_max_docs=1).load()\n",
    "print(len(wikidoc))\n",
    "wikidoc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
